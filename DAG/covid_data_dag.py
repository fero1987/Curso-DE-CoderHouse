# -*- coding: utf-8 -*-
"""Entregas Curso DE CoderHouse - Fernando Martínez.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-cq0EXViJyL9xZQrWP4CJRyv_5Uwz1rQ

## **Entregable 1 - Fernando Martínez (comisión Jueves)**
"""

# Instalo las bibliotecas necesarias
!pip install requests

# Importo las bibliotecas necesarias:
import requests
import json
import pandas as pd
import psycopg2
from io import StringIO

# Nueva URL de la API para obtener los datos diarios de COVID-19 para Estados Unidos
url = 'https://api.covidtracking.com/v1/us/daily.json'

# Realizo la solicitud HTTP a la API
response = requests.get(url)

# Obtengo los datos en formato JSON
data = response.json()

# Selecciono las columnas relevantes (al menos 10 variables)
columnas = ['date', 'positive', 'death', 'positiveIncrease', 'deathIncrease', 'totalTestResults', 'hospitalizedCurrently', 'recovered', 'total', 'totalTestResultsIncrease']
datos = []

# Extraigo los datos para cada día
for registro in data:
    registro_seleccionado = {columna: registro[columna] for columna in columnas if columna in registro}
    datos.append(registro_seleccionado)

# Creo el dataframe de Pandas
df = pd.DataFrame(datos)

# Renombro las columnas
nombres_columnas = {
    'date': 'submission_date',
    'positive': 'tot_cases',
    'death': 'tot_death',
    'positiveIncrease': 'new_case',
    'deathIncrease': 'new_death',
    'totalTestResults': 'total_test_results',
    'hospitalizedCurrently': 'hospitalized_currently',
    'recovered': 'recovered',
    'total': 'total',
    'totalTestResultsIncrease': 'total_test_results_increase'
}
df = df.rename(columns=nombres_columnas)

# Muestro el dataframe
print(df)

# Elimino las filas que no aportan valor por tener cero, Nan, None o nulos
import numpy as np

# Defino las columnas a verificar
columns_to_check = df.columns[1:]  # Excluir la columna "submission_date"

# Eliminar filas donde todas las columnas (excepto "submission_date") son cero, NaN, None o nulas
df_cleaned = df.dropna(subset=columns_to_check, how='all')
df_cleaned = df_cleaned.replace({0: np.nan, 'None': np.nan, None: np.nan})
df_cleaned = df_cleaned.dropna(how='all', subset=columns_to_check)

# Mostrar el DataFrame resultante
df = df_cleaned
print(df)

import psycopg2
from io import StringIO

# Conexión a Amazon Redshift
host = 'data-engineer-cluster.cyhh5bfevlmn.us-east-1.redshift.amazonaws.com'
port = 5439
database = 'data-engineer-database'
user = 'fgmartinez87_coderhouse'
password = '7c92hMs3M1' # ver contraseña en la entrega

# Creo la conexión a Amazon Redshift
conn = psycopg2.connect(
    host=host,
    port=port,
    database=database,
    user=user,
    password=password
)

# Creo la tabla en Redshift con diststyle even y sortkeys
create_table_query = '''
CREATE TABLE IF NOT EXISTS covid_data (
    submission_date INT,
    tot_cases INT,
    tot_death INT,
    new_case INT,
    new_death INT,
    total_test_results INT,
    hospitalized_currently INT,
    recovered INT,
    total INT,
    total_test_results_increase INT
)
DISTSTYLE EVEN
SORTKEY (submission_date);
'''
with conn.cursor() as cur:
     cur.execute(create_table_query)
     conn.commit()

# Realizo la consulta en Redshift para ver si se creo la tabla
query = 'SELECT * FROM covid_data;'
df_result = pd.read_sql_query(query, conn)

# Muestro el resultado
print(df_result)

"""
## **Entregable 2 - Fernando Martínez (comisión Jueves) con correcciones**
"""

# Inserto los datos del df
insert_query = 'INSERT INTO covid_data VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s);'
data_to_insert = [tuple(row) for row in df.values]
with conn.cursor() as cur:
    cur.executemany(insert_query, data_to_insert)
    conn.commit()

# Realizo la consulta en Redshift para ver si se cargó la data
query = 'SELECT * FROM covid_data;'
df_result = pd.read_sql_query(query, conn)

# Muestro el resultado
print(df_result)

# Cuento la cantidad de registros para validar
with conn.cursor() as cur:
    cur.execute("SELECT COUNT(*) FROM covid_data")
    count = cur.fetchone()[0]
    print(f"Cantidad de registros en la tabla covid_data: {count}")

# Quiero validar que no hayan duplicados
with conn.cursor() as cur:
    cur.execute("SELECT COUNT(*) FROM (SELECT DISTINCT * FROM covid_data) AS unique_records;")
    count = cur.fetchone()[0]
    print(f"Cantidad de registros únicos en la tabla covid_data: {count}")

# Query para borrar la tabla
with conn.cursor() as cur:
    truncate_query = 'DROP TABLE covid_data;'
    cur.execute(truncate_query)
    conn.commit()

# Inserto los mismos registros dos veces para generar duplicados
insert_query = 'INSERT INTO covid_data VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s);'
data_to_insert = [tuple(row) for row in df.values]
with conn.cursor() as cur:
    cur.executemany(insert_query, data_to_insert)
    conn.commit()

# Cuento la cantidad de registros para validar
with conn.cursor() as cur:
    cur.execute("SELECT COUNT(*) FROM covid_data")
    count = cur.fetchone()[0]
    print(f"Cantidad de registros en la tabla covid_data: {count}")

# Query para eliminar duplicados utilizando una tabla temporal en memoria
with conn.cursor() as cur:
    # Creo una tabla temporal en memoria sin duplicados
    cur.execute("CREATE TEMP TABLE covid_data_temp AS SELECT DISTINCT * FROM covid_data;")

    # Vacío la tabla original
    cur.execute("TRUNCATE TABLE covid_data;")

    # Inserto los datos únicos desde la tabla temporal a la tabla original
    cur.execute("INSERT INTO covid_data SELECT * FROM covid_data_temp;")

    # Descarto la tabla temporal en memoria
    cur.execute("DROP TABLE covid_data_temp;")

    # Confirmo los cambios
    conn.commit()

    # Obtengo la cantidad de registros después de eliminar duplicados
    cur.execute("SELECT COUNT(*) FROM covid_data;")
    count = cur.fetchone()[0]
    print(f"Cantidad de registros en la tabla covid_data después de eliminar duplicados: {count}")